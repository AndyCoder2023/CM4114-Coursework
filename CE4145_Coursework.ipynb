{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2sDr56AwyTigW5a6h7+Dv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndyCoder2023/CM4114-Coursework/blob/main/CE4145_Coursework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KieNkNJyC2ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"AndyCoder2023\"\n",
        "!git config --global user.email \"a.webster2@rgu.ac.uk\""
      ],
      "metadata": {
        "id": "PkOXf6695s8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote set-url origin https://AndyCoder2023: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@github.com/AndyCoder2023/CE4145-NLP-Coursework.git"
      ],
      "metadata": {
        "id": "9a-WcD_G9uc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l CE4145_Coursework.ipynb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzT9LoLc_b48",
        "outputId": "68df66fb-83be-4ae7-b587-1e4ec284489f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 46543 Oct 12 10:37 CE4145_Coursework.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUEYQ0eiZ5SP",
        "outputId": "f4acc6d3-7d07-4971-8a07-1318b2ccffc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git fetch origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cslDTpUVZe5R",
        "outputId": "801a78e0-816b-4a4a-a9ba-272b5ae0e174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/AndyCoder2023/CE4145-NLP-Coursework\n",
            " * branch            main       -> FETCH_HEAD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add ."
      ],
      "metadata": {
        "id": "IGUaGABqclXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"fixing the git structure\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDDsxsIwcofF",
        "outputId": "1c2518a6-0068-44a0-f947-870081ab5215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main af08957] fixing the git structure\n",
            " 1 file changed, 709 deletions(-)\n",
            " delete mode 100644 CE4145_Coursework_backup.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxH-Vo1l8Twh",
        "outputId": "6fa352e5-4af0-4f06-988a-5a7e0aa30fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enumerating objects: 3, done.\n",
            "Counting objects:  33% (1/3)\rCounting objects:  66% (2/3)\rCounting objects: 100% (3/3)\rCounting objects: 100% (3/3), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects:  50% (1/2)\rCompressing objects: 100% (2/2)\rCompressing objects: 100% (2/2), done.\n",
            "Writing objects:  50% (1/2)\rWriting objects: 100% (2/2)\rWriting objects: 100% (2/2), 237 bytes | 237.00 KiB/s, done.\n",
            "Total 2 (delta 1), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas:   0% (0/1)\u001b[K\rremote: Resolving deltas: 100% (1/1)\u001b[K\rremote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
            "To https://github.com/AndyCoder2023/CE4145-NLP-Coursework.git\n",
            "   f5654be..af08957  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git branch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVAr_F_RZ0A0",
        "outputId": "1682ea2f-da67-4c55-c9ab-d38612de1c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* \u001b[32mmain\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote -v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLrIBxJqWlKG",
        "outputId": "2e8f8886-c336-4872-f5fe-f31ec0f981cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "origin\thttps://AndyCoder2023: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@github.com/AndyCoder2023/CE4145-NLP-Coursework.git (fetch)\n",
            "origin\thttps://AndyCoder2023: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@github.com/AndyCoder2023/CE4145-NLP-Coursework.git (push)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ixnGCbx8MFk",
        "outputId": "69789649-32ee-4b8a-d2c1-6c58e9870366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzSXbMgy8WCi",
        "outputId": "878834dc-d9af-48f2-a4d5-5d00b5e8f089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CE4145_Coursework.ipynb  README.md  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SqiQMNY8tzy",
        "outputId": "f04e97d5-8341-4247-c196-329e08614507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "CE4145_Coursework.ipynb  README.md  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhzTKUg59hQN",
        "outputId": "6fab498b-9e75-407c-f6b7-5bc538da4f05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".  ..  CE4145_Coursework.ipynb\t.config  .git  README.md  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Describe the dataset and the task to be performed**\n",
        "\n",
        "# Dataset\n",
        "\n",
        "The dataset consists of a movie evaluation database. The database is from a easy hierarchical decision model which has been made to present an expert system which is decision making. The task that is to be performed for the dataset will consist of two different pipelines which will compare the best strategy for the given task to be performed on the movie dataset. The two pipelines that will be used are\n",
        "\n",
        "\n",
        "\n",
        "Merchán-Rivera, P. (2025). movies-dataset [Dataset]. Hugging Face. https://huggingface.co/datasets/Pablinho/movies-dataset."
      ],
      "metadata": {
        "id": "gibHCW4NBSdD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "test data"
      ],
      "metadata": {
        "id": "9hAgjTFq4F7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Y7XqIUru731F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd #we will use pandas to view data in dataframes\n",
        "import io #io we use to load the data after uploading (as colab uses dictionaries to store uploaded files)\n",
        "from google.colab import files #finally, we import the files package from google.colab framework to be able to upload files\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset directly\n",
        "movie_df = pd.read_csv(\"hf://datasets/Pablinho/movies-dataset/9000plus.csv\")\n",
        "\n",
        "print(movie_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkkGvi11CDrh",
        "outputId": "8af81bd0-6f80-4ef6-d82d-1b11c56d7c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Release_Date                                 Title  \\\n",
            "0      2021-12-15               Spider-Man: No Way Home   \n",
            "1      2022-03-01                            The Batman   \n",
            "2      2022-02-25                               No Exit   \n",
            "3      2021-11-24                               Encanto   \n",
            "4      2021-12-22                        The King's Man   \n",
            "...           ...                                   ...   \n",
            "9832   1973-10-15                              Badlands   \n",
            "9833   2020-10-01                      Violent Delights   \n",
            "9834   2016-05-06                          The Offering   \n",
            "9835   2021-03-31  The United States vs. Billie Holiday   \n",
            "9836   1984-09-23                               Threads   \n",
            "\n",
            "                                               Overview  Popularity  \\\n",
            "0     Peter Parker is unmasked and no longer able to...    5083.954   \n",
            "1     In his second year of fighting crime, Batman u...    3827.658   \n",
            "2     Stranded at a rest stop in the mountains durin...    2618.087   \n",
            "3     The tale of an extraordinary family, the Madri...    2402.201   \n",
            "4     As a collection of history's worst tyrants and...    1895.511   \n",
            "...                                                 ...         ...   \n",
            "9832  A dramatization of the Starkweather-Fugate kil...      13.357   \n",
            "9833  A female vampire falls in love with a man she ...      13.356   \n",
            "9834  When young and successful reporter Jamie finds...      13.355   \n",
            "9835  Billie Holiday spent much of her career being ...      13.354   \n",
            "9836  Documentary style account of a nuclear holocau...      13.354   \n",
            "\n",
            "     Vote_Count Vote_Average Original_Language  \\\n",
            "0          8940          8.3                en   \n",
            "1          1151          8.1                en   \n",
            "2           122          6.3                en   \n",
            "3          5076          7.7                en   \n",
            "4          1793          7.0                en   \n",
            "...         ...          ...               ...   \n",
            "9832        896          7.6                en   \n",
            "9833          8          3.5                es   \n",
            "9834         94          5.0                en   \n",
            "9835        152          6.7                en   \n",
            "9836        186          7.8                en   \n",
            "\n",
            "                                   Genre  \\\n",
            "0     Action, Adventure, Science Fiction   \n",
            "1               Crime, Mystery, Thriller   \n",
            "2                               Thriller   \n",
            "3     Animation, Comedy, Family, Fantasy   \n",
            "4       Action, Adventure, Thriller, War   \n",
            "...                                  ...   \n",
            "9832                        Drama, Crime   \n",
            "9833                              Horror   \n",
            "9834           Mystery, Thriller, Horror   \n",
            "9835               Music, Drama, History   \n",
            "9836         War, Drama, Science Fiction   \n",
            "\n",
            "                                             Poster_Url  \n",
            "0     https://image.tmdb.org/t/p/original/1g0dhYtq4i...  \n",
            "1     https://image.tmdb.org/t/p/original/74xTEgt7R3...  \n",
            "2     https://image.tmdb.org/t/p/original/vDHsLnOWKl...  \n",
            "3     https://image.tmdb.org/t/p/original/4j0PNHkMr5...  \n",
            "4     https://image.tmdb.org/t/p/original/aq4Pwv5Xeu...  \n",
            "...                                                 ...  \n",
            "9832  https://image.tmdb.org/t/p/original/z81rBzHNgi...  \n",
            "9833  https://image.tmdb.org/t/p/original/4b6HY7rud6...  \n",
            "9834  https://image.tmdb.org/t/p/original/h4uMM1wOhz...  \n",
            "9835  https://image.tmdb.org/t/p/original/vEzkxuE2sJ...  \n",
            "9836  https://image.tmdb.org/t/p/original/lBhU4U9Eeh...  \n",
            "\n",
            "[9837 rows x 9 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PrOAVCuNCDx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5BZ8F1UbZj9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bd1dda2-e90f-44aa-e5cb-0730ab19328a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Release_Date                                 Title  \\\n",
            "0      2021-12-15               Spider-Man: No Way Home   \n",
            "1      2022-03-01                            The Batman   \n",
            "2      2022-02-25                               No Exit   \n",
            "3      2021-11-24                               Encanto   \n",
            "4      2021-12-22                        The King's Man   \n",
            "...           ...                                   ...   \n",
            "9832   1973-10-15                              Badlands   \n",
            "9833   2020-10-01                      Violent Delights   \n",
            "9834   2016-05-06                          The Offering   \n",
            "9835   2021-03-31  The United States vs. Billie Holiday   \n",
            "9836   1984-09-23                               Threads   \n",
            "\n",
            "                                               Overview  Popularity  \\\n",
            "0     Peter Parker is unmasked and no longer able to...    5083.954   \n",
            "1     In his second year of fighting crime, Batman u...    3827.658   \n",
            "2     Stranded at a rest stop in the mountains durin...    2618.087   \n",
            "3     The tale of an extraordinary family, the Madri...    2402.201   \n",
            "4     As a collection of history's worst tyrants and...    1895.511   \n",
            "...                                                 ...         ...   \n",
            "9832  A dramatization of the Starkweather-Fugate kil...      13.357   \n",
            "9833  A female vampire falls in love with a man she ...      13.356   \n",
            "9834  When young and successful reporter Jamie finds...      13.355   \n",
            "9835  Billie Holiday spent much of her career being ...      13.354   \n",
            "9836  Documentary style account of a nuclear holocau...      13.354   \n",
            "\n",
            "     Vote_Count Vote_Average Original_Language  \\\n",
            "0          8940          8.3                en   \n",
            "1          1151          8.1                en   \n",
            "2           122          6.3                en   \n",
            "3          5076          7.7                en   \n",
            "4          1793          7.0                en   \n",
            "...         ...          ...               ...   \n",
            "9832        896          7.6                en   \n",
            "9833          8          3.5                es   \n",
            "9834         94          5.0                en   \n",
            "9835        152          6.7                en   \n",
            "9836        186          7.8                en   \n",
            "\n",
            "                                   Genre  \\\n",
            "0     Action, Adventure, Science Fiction   \n",
            "1               Crime, Mystery, Thriller   \n",
            "2                               Thriller   \n",
            "3     Animation, Comedy, Family, Fantasy   \n",
            "4       Action, Adventure, Thriller, War   \n",
            "...                                  ...   \n",
            "9832                        Drama, Crime   \n",
            "9833                              Horror   \n",
            "9834           Mystery, Thriller, Horror   \n",
            "9835               Music, Drama, History   \n",
            "9836         War, Drama, Science Fiction   \n",
            "\n",
            "                                             Poster_Url  \n",
            "0     https://image.tmdb.org/t/p/original/1g0dhYtq4i...  \n",
            "1     https://image.tmdb.org/t/p/original/74xTEgt7R3...  \n",
            "2     https://image.tmdb.org/t/p/original/vDHsLnOWKl...  \n",
            "3     https://image.tmdb.org/t/p/original/4j0PNHkMr5...  \n",
            "4     https://image.tmdb.org/t/p/original/aq4Pwv5Xeu...  \n",
            "...                                                 ...  \n",
            "9832  https://image.tmdb.org/t/p/original/z81rBzHNgi...  \n",
            "9833  https://image.tmdb.org/t/p/original/4b6HY7rud6...  \n",
            "9834  https://image.tmdb.org/t/p/original/h4uMM1wOhz...  \n",
            "9835  https://image.tmdb.org/t/p/original/vEzkxuE2sJ...  \n",
            "9836  https://image.tmdb.org/t/p/original/lBhU4U9Eeh...  \n",
            "\n",
            "[9837 rows x 9 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd #we will use pandas to view data in dataframes\n",
        "import io #io we use to load the data after uploading (as colab uses dictionaries to store uploaded files)\n",
        "from google.colab import files #finally, we import the files package from google.colab framework to be able to upload files\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset directly\n",
        "movie_df = pd.read_csv(\"hf://datasets/Pablinho/movies-dataset/9000plus.csv\")\n",
        "\n",
        "print(movie_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_keys = movie_df.columns.tolist()\n",
        "df_keys.remove(\"Release_Date\")\n",
        "\n",
        "x = movie_df[df_keys].to_numpy() #next we convert the feature columns into a numpy array\n",
        "y = movie_df[['Release_Date']].to_numpy()\n",
        "\n",
        "y = y.reshape(len(y),) #reshaping removes that annoying python warning that fills the cell output"
      ],
      "metadata": {
        "id": "pwbvi9BPcTCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np #import numpy to enable array functionality\n",
        "\n",
        "# Select numerical feature columns using their names\n",
        "feature_columns = ['Popularity', 'Vote_Count']\n",
        "x = movie_df[feature_columns].to_numpy() #next we convert the feature columns into a numpy array\n",
        "\n",
        "# Select the label column using its name\n",
        "y = movie_df[['Vote_Average']].to_numpy() #swiftly followed by the label column - and our dataset is now ready\n",
        "\n",
        "#print(x) #feel free to uncomment and check the output\n",
        "#print(y)"
      ],
      "metadata": {
        "id": "ErgWRsJhD1N7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (movie_df)\n",
        "# Reference -"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpMaaBRSD5On",
        "outputId": "bb43ed6b-8d0a-4d25-8b92-ead4ec591a70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Release_Date                                 Title  \\\n",
            "0      2021-12-15               Spider-Man: No Way Home   \n",
            "1      2022-03-01                            The Batman   \n",
            "2      2022-02-25                               No Exit   \n",
            "3      2021-11-24                               Encanto   \n",
            "4      2021-12-22                        The King's Man   \n",
            "...           ...                                   ...   \n",
            "9832   1973-10-15                              Badlands   \n",
            "9833   2020-10-01                      Violent Delights   \n",
            "9834   2016-05-06                          The Offering   \n",
            "9835   2021-03-31  The United States vs. Billie Holiday   \n",
            "9836   1984-09-23                               Threads   \n",
            "\n",
            "                                               Overview  Popularity  \\\n",
            "0     Peter Parker is unmasked and no longer able to...    5083.954   \n",
            "1     In his second year of fighting crime, Batman u...    3827.658   \n",
            "2     Stranded at a rest stop in the mountains durin...    2618.087   \n",
            "3     The tale of an extraordinary family, the Madri...    2402.201   \n",
            "4     As a collection of history's worst tyrants and...    1895.511   \n",
            "...                                                 ...         ...   \n",
            "9832  A dramatization of the Starkweather-Fugate kil...      13.357   \n",
            "9833  A female vampire falls in love with a man she ...      13.356   \n",
            "9834  When young and successful reporter Jamie finds...      13.355   \n",
            "9835  Billie Holiday spent much of her career being ...      13.354   \n",
            "9836  Documentary style account of a nuclear holocau...      13.354   \n",
            "\n",
            "     Vote_Count Vote_Average Original_Language  \\\n",
            "0          8940          8.3                en   \n",
            "1          1151          8.1                en   \n",
            "2           122          6.3                en   \n",
            "3          5076          7.7                en   \n",
            "4          1793          7.0                en   \n",
            "...         ...          ...               ...   \n",
            "9832        896          7.6                en   \n",
            "9833          8          3.5                es   \n",
            "9834         94          5.0                en   \n",
            "9835        152          6.7                en   \n",
            "9836        186          7.8                en   \n",
            "\n",
            "                                   Genre  \\\n",
            "0     Action, Adventure, Science Fiction   \n",
            "1               Crime, Mystery, Thriller   \n",
            "2                               Thriller   \n",
            "3     Animation, Comedy, Family, Fantasy   \n",
            "4       Action, Adventure, Thriller, War   \n",
            "...                                  ...   \n",
            "9832                        Drama, Crime   \n",
            "9833                              Horror   \n",
            "9834           Mystery, Thriller, Horror   \n",
            "9835               Music, Drama, History   \n",
            "9836         War, Drama, Science Fiction   \n",
            "\n",
            "                                             Poster_Url  \n",
            "0     https://image.tmdb.org/t/p/original/1g0dhYtq4i...  \n",
            "1     https://image.tmdb.org/t/p/original/74xTEgt7R3...  \n",
            "2     https://image.tmdb.org/t/p/original/vDHsLnOWKl...  \n",
            "3     https://image.tmdb.org/t/p/original/4j0PNHkMr5...  \n",
            "4     https://image.tmdb.org/t/p/original/aq4Pwv5Xeu...  \n",
            "...                                                 ...  \n",
            "9832  https://image.tmdb.org/t/p/original/z81rBzHNgi...  \n",
            "9833  https://image.tmdb.org/t/p/original/4b6HY7rud6...  \n",
            "9834  https://image.tmdb.org/t/p/original/h4uMM1wOhz...  \n",
            "9835  https://image.tmdb.org/t/p/original/vEzkxuE2sJ...  \n",
            "9836  https://image.tmdb.org/t/p/original/lBhU4U9Eeh...  \n",
            "\n",
            "[9837 rows x 9 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Describe the representation learning\n",
        "approach adopted. **bold text**\n",
        "\n",
        "# Representation Learning\n",
        "\n",
        "The representation learning approach that will used will consist of using activation functions such as Sigmoid and linear. Sigmoid can be used to narrow down the neuron's preactivation that is between the number 0 & 1. The main learning approach that will be used is the activation function called Relu. The Relu function will be used to convert an output that is in a layer to then display a vector of probabilities. The classification of the model will be categorical. StratifiedKFold & MLPClassifier will be used for the classification. Model will have 64 neuron layers with the batch size of 65.\n",
        "\n",
        "https://colab.research.google.com/drive/1H9Mjy7PUmcFWx0jzWxB3oCDlZf9twfF6?usp=sharing#scrollTo=IWPDc9_Lt3kr"
      ],
      "metadata": {
        "id": "I4fSC1u8Ebqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd #we will use pandas to view data in dataframes\n",
        "import io #io we use to load the data after uploading (as colab uses dictionaries to store uploaded files)\n",
        "from google.colab import files #finally, we import the files package from google.colab framework to be able to upload files\n",
        "\n",
        "import random\n",
        "random.seed(1337)"
      ],
      "metadata": {
        "id": "p6R7WY6IInmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "fVR-oPRnlX6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "cdeea056-1014-4f96-cce3-01d15f16bc7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "kLKt380tk-H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files, drive #import colab functionality\n",
        "#drive.mount(\"/content/drive\") #mount the drive within our virtual machine\n",
        "\n",
        "path = 'hf://datasets/Pablinho/movies-dataset/9000plus.csv' #identify the path to our dataset - remember to update to your details!\n",
        "movie_df = pd.read_csv(path) #pd read csv as normal"
      ],
      "metadata": {
        "id": "uSUngo74lAkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_keys = movie_df.columns.tolist()\n",
        "df_keys.remove(\"Release_Date\")\n",
        "\n",
        "x = movie_df[df_keys].to_numpy() #next we convert the feature columns into a numpy array\n",
        "y = movie_df[['Release_Date']].to_numpy()\n",
        "\n",
        "y = y.reshape(len(y),) #reshaping removes that annoying python warning that fills the cell output"
      ],
      "metadata": {
        "id": "rCP5ZiNZnF61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neural_network import MLPClassifier #importing the mlp model\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "acc_scores = []\n",
        "\n",
        "# Select numerical feature columns using their names\n",
        "feature_columns = ['Popularity', 'Vote_Count']\n",
        "\n",
        "# Remove rows where 'Vote_Average' is not a number (e.g., contains the string 'Vote_Average')\n",
        "movie_df_cleaned = movie_df[pd.to_numeric(movie_df['Vote_Average'], errors='coerce').notna()].copy()\n",
        "\n",
        "x = movie_df_cleaned[feature_columns].to_numpy()\n",
        "\n",
        "# Select the label column using its name\n",
        "# For classification, the target should be categorical.\n",
        "# Since the error suggests string conversion issues with the target variable,\n",
        "# and given the context of movie ratings, it's likely a regression task,\n",
        "# but the use of StratifiedKFold and MLPClassifier (often used for classification)\n",
        "# suggests a potential mismatch or an attempt to classify binned ratings.\n",
        "# Assuming a classification task on binned vote averages for now.\n",
        "# We need to discretize 'Vote_Average' into classes.\n",
        "# Let's create 10 bins for simplicity, matching the num_classes later.\n",
        "y = pd.cut(pd.to_numeric(movie_df_cleaned['Vote_Average']), bins=10, labels=False).to_numpy()\n",
        "\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5)\n",
        "for train, test in kf.split(x,y):\n",
        "\n",
        "  # Next we instantiate the model - params include:\n",
        "  # - hidden_layer_sizes - defining the number of layers and neurons in each layer. We use a single layer of 64 neurons.\n",
        "  # - activation - the activation function. We use ReLU here.\n",
        "  # - batch_size - the number of training examples which are submitted through a forward pass before backpropagation is performed.\n",
        "  # - max_iter - the number of training iterations using the full training set (i.e. epochs).\n",
        "  model = MLPClassifier(hidden_layer_sizes=(64,), activation=\"relu\", batch_size=64, max_iter=100, random_state=42) # Increased max_iter for better convergence, added random_state\n",
        "  x_train, x_test, y_train, y_test = x[train], x[test], y[train], y[test]\n",
        "\n",
        "  model.fit(x_train, y_train)\n",
        "  predictions = model.predict(x_test)\n",
        "\n",
        "  acc = accuracy_score(predictions, y_test)\n",
        "  acc_scores.append(acc)\n",
        "\n",
        "print(acc_scores)\n",
        "\n",
        "#AI supported with fixing code.\n",
        "\n",
        "# Reference - https://colab.research.google.com/drive/1H9Mjy7PUmcFWx0jzWxB3oCDlZf9twfF6?usp=sharing#scrollTo=4fdDprVp0zpR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvFUhdYUgz6E",
        "outputId": "394755ab-c5f7-4222-ead5-01014cd9514e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.40895218718209564, 0.35725190839694654, 0.3374045801526718, 0.36743002544529263, 0.4203562340966921]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCP5ZiZnF61"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Describe the theory behind the\n",
        "algorithms to be applied. **bold text**\n",
        "\n",
        "# Algorithms"
      ],
      "metadata": {
        "id": "b34dhQrEIoJM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The two algorithms that will implemented will consist of Convolutional Neural network and"
      ],
      "metadata": {
        "id": "IWbMMkS1mrUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np #For the array functions\n",
        "from tensorflow import keras #we will only be using tensorflow as a backend, so we will import keras via their implementation\n",
        "# Corrected import: import layers directly from keras\n",
        "from keras import layers #we will use the readable keras implementation of the conv/reccurent layers"
      ],
      "metadata": {
        "id": "dkWanNIQI8uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Next we will preprocess the dataset\n",
        "\n",
        "#To start we will normalise the contents of the arrays. We will use min max normalisation, where we know the maximum value is 255\n",
        "#This will scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "#The next setps require us to identify the number of classes - in our problem we have 10\n",
        "num_classes = 10\n",
        "\n",
        "#Then we convert class vectors to one hot vectors - i.e. vectors of the size of number of classes, with a 1 in the class index and a 0 in every other class index\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "0J-Jc4LVpdDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential( #first we create a model and specify we are using the Sequential configuration within Keras\n",
        "    [\n",
        "        keras.Input(shape=(28,28,1)), #Next we specify the size of our input layer. For MNIST, this will be 28 pixels by 28 pixels. The 1 indicates there is only a single colour dimension (black and white)\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"), #Next we add a convolution layer.  We state there will be 32 filters, and each filter will be size 3 x 3\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)), #After the convolution layer we add a MP layer. The MP layer will summarise 2x2 portions of our activation matrix from our convolution layer\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"), #we can repeat as often as necessary\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(), #Eventually, we flatten the output of the last MP layer, so that it becomes a vector instead of a matrix\n",
        "        layers.Dense(num_classes, activation=\"softmax\"), #We then send to our outpt layyer (which has 10 neurons, one for each class) and a softmax activation function\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "k-GMJOEgpgGS",
        "outputId": "54ae238d-4d87-429c-9506-492bc7434358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m16,010\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,010</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m34,826\u001b[0m (136.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,826</span> (136.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m34,826\u001b[0m (136.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,826</span> (136.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128 #the batch size is the number of examples the model will view before summing and backpropagating the loss\n",
        "epochs = 10 #epochs are the number of training iterations examining the full training set\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"]) #We can set the model to compile. We call some inbuilt functions for our loss, optimizer and metrics respectively. Can you identify them from the lectures?\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs) #Finally, we train the model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "SRqEu2eXpjYD",
        "outputId": "acac27fa-8222-4942-a251-3a6bb5576050"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None, 10, 10), output.shape=(None, 10)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2871876223.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sgd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#We can set the model to compile. We call some inbuilt functions for our loss, optimizer and metrics respectively. Can you identify them from the lectures?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Finally, we train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/nn.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m    660\u001b[0m         )\n\u001b[1;32m    661\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[0;34m\"Arguments `target` and `output` must have the same rank \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;34m\"(ndim). Received: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None, 10, 10), output.shape=(None, 10)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We can then test our model on the test set\n",
        "score = model.evaluate(x_test, y_test, verbose=0) #the model evaluate function contains some useful metrics to evaluate our model. We set verbose to 0 so we can print the ones we are interested in\n",
        "print(\"Test loss:\", score[0]) #Let's look at loss\n",
        "print(\"Test accuracy:\", score[1]) #And accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "jfxwHRujppBd",
        "outputId": "24c26a9b-e407-4eaf-8d78-b4b902c53041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None, 10, 10), output.shape=(None, 10)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2095174137.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#We can then test our model on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#the model evaluate function contains some useful metrics to evaluate our model. We set verbose to 0 so we can print the ones we are interested in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Let's look at loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#And accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/nn.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m    660\u001b[0m         )\n\u001b[1;32m    661\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[0;34m\"Arguments `target` and `output` must have the same rank \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;34m\"(ndim). Received: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None, 10, 10), output.shape=(None, 10)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Describe the evaluation process, and\n",
        "analyse the results. **bold text**\n",
        "\n",
        "# Evaluation"
      ],
      "metadata": {
        "id": "TYIwd6xdI8hp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "p9Qo6WtGsekN"
      }
    }
  ]
}